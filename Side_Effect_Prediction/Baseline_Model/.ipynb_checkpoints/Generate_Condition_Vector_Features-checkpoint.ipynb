{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8011\n",
      "Loading Files Done\n"
     ]
    }
   ],
   "source": [
    "# Reading the Patient Feature and Id Json file\n",
    "\n",
    "import json\n",
    "import math\n",
    "from mlxtend.preprocessing import OnehotTransactions\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('Data/Final_Datasets/Total_Patients_Personal_Details_Features_File.txt') as data_file:    \n",
    "    patient_data = json.load(data_file)   # yaml.safe_loads produces strings rather than unicode strings as in json.load\n",
    "\n",
    "with open('Data/Final_Datasets/Selected_Patient_Id.txt') as data_file:    \n",
    "    patient_id = json.load(data_file)   # yaml.safe_loads produces strings rather than unicode strings as in json.load\n",
    "    \n",
    "print len(patient_data)\n",
    "print \"Loading Files Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the Test\n",
      "Total Number of evaluations 42075\n"
     ]
    }
   ],
   "source": [
    "# Testing for Datasets\n",
    "\n",
    "# Checking is still some case of no Side Effect being mentioned\n",
    "for patient in patient_data.keys():\n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "        if patient_data[patient][\"Treatments List\"][drug][\"Side Effects\"] == -1:\n",
    "            print \"You are Screwed\"\n",
    "\n",
    "print \"Done with the Test\"\n",
    "total_eval_count = 0\n",
    "\n",
    "# Counting total number of evaluations\n",
    "for patient in patient_data.keys():\n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "            total_eval_count = total_eval_count + 1\n",
    "\n",
    "print \"Total Number of evaluations\",\n",
    "print total_eval_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8011\n",
      "2109\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "patient_condition_data = {}\n",
    "\n",
    "# Making a vocabulary of all the conditions: primary and other listed by all the patients in dataset.\n",
    "# This vocabulary is stored in train_data. It is a dictionary with key as condition name and value as 1.0 if condition is \n",
    "# from a class of primary condition of patients and 0.5 if the condition is from class of other conditions.\n",
    "\n",
    "# Concatenating both primary and secodary conditions for each patient and assiging the concatenated list of conditions \n",
    "# for each patient in patient_condition_data. Key is patient and value is the concatenated list.\n",
    "# While making the concatenated list for each patient, we add \"P_\" at start of primary condition id \n",
    "# and \"O_\" for other condition id. This is to differentiate as there would a primary condition with id 1 and also an \n",
    "# other condition with id 1, so to differentiate between same id primary and other conditions, add these strings.\n",
    "\n",
    "for patient in patient_data.keys():\n",
    "    condition_list = []\n",
    "    feature = patient_data[patient][\"Primary Condition\"]\n",
    "    if feature != -1:\n",
    "        condition_list.append(\"P_\" + str(feature) )\n",
    "        train_data[ \"P_\" + str(feature) ] = 1             # Assigning score 1 for primary condition\n",
    "    \n",
    "    feature = patient_data[patient][\"Other conditions\"]\n",
    "    if feature != -1:\n",
    "        for item in feature:\n",
    "            condition_list.append( \"O_\" + str(item))\n",
    "            train_data[ \"O_\" + str(item) ] = 0.5          # Assigning score 0.5 for other conditions\n",
    " \n",
    "    patient_condition_data[ patient ] = condition_list\n",
    "\n",
    "f = open(\"Data/Final_Datasets/Condition_Features/Patient_Condition_Data.txt\",\"w\")\n",
    "f.write( json.dumps(patient_condition_data, indent=3, sort_keys=True) )\n",
    "f.close()\n",
    "\n",
    "f = open(\"Data/Final_Datasets/Condition_Features/Conditions_Vocaulary.txt\", \"w\")\n",
    "f.write( json.dumps(train_data, indent=3, sort_keys=True) )\n",
    "f.close()\n",
    "\n",
    "print len(patient_condition_data)\n",
    "print len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generating a vectorised representation for each patient's concatenated condition list\n",
    "# Vector is of size of length of vocabualary i.e. len(train_data.keys())\n",
    "# Every condition from patient's list of conditions i.e. patient_condition_data[patient] is compared \n",
    "# with list of conditions in vocabulary. \n",
    "# For those conditions of vocab present in patient's list condition, assign the score 1 or 0.5 depending on whether its primary or other condition\n",
    "# Else assign zero for that component of vector.\n",
    "\n",
    "vectorised_data ={}\n",
    "for patient in patient_condition_data:\n",
    "    temp = []\n",
    "    for condition in train_data.keys():\n",
    "        if condition in patient_condition_data[patient]:\n",
    "            temp.append( train_data[condition] )\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    vectorised_data[ patient ] = temp\n",
    "\n",
    "f = open(\"Data/Final_Datasets/Condition_Features/Vectorised_Patient_Condition.txt\", \"w\")\n",
    "f.write( json.dumps(vectorised_data, indent=3, sort_keys=True) )\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
