{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8011\n",
      "Loading Files Done\n",
      "Done with the Test\n",
      "Total Number of evaluations 42075\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Reading the patient feature and id file.\n",
    "\n",
    "with open('Data/Final_Datasets/Total_Patients_Personal_Details_Features_File.txt') as data_file:    \n",
    "    patient_data = json.load(data_file)   # yaml.safe_loads produces strings rather than unicode strings as in json.load\n",
    "\n",
    "with open('Data/Final_Datasets/Id_Mapping_Files/Selected_Patient_Id.txt') as data_file:    \n",
    "    patient_id = json.load(data_file)   # yaml.safe_loads produces strings rather than unicode strings as in json.load\n",
    "    \n",
    "print len(patient_data)\n",
    "print \"Loading Files Done\"\n",
    "\n",
    "# Testing for Datasets\n",
    "\n",
    "# Checking is still some case of no Side Effect being mentioned\n",
    "for patient in patient_data.keys():\n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "        if patient_data[patient][\"Treatments List\"][drug][\"Side Effects\"] == -1:\n",
    "            print \"You are Screwed\"\n",
    "\n",
    "print \"Done with the Test\"\n",
    "total_eval_count = 0\n",
    "\n",
    "for patient in patient_data.keys():\n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "            total_eval_count = total_eval_count + 1\n",
    "\n",
    "print \"Total Number of evaluations\",\n",
    "print total_eval_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "2813\n"
     ]
    }
   ],
   "source": [
    "# Making a list of all side effects: side_effect_repeated\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "side_effect_repeated_list = []\n",
    "for patient in patient_data.keys():\n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "        feature = patient_data[patient][\"Treatments List\"][drug][\"Side Effects\"]\n",
    "        for item in feature:\n",
    "            side_effect_repeated_list.append(item)\n",
    "\n",
    "# Making a dictionary of side effect: side_effect_dict: key as side effect and value as total number of times it gets repeated in dataset            \n",
    "side_effect_dict= {}\n",
    "for item in side_effect_repeated_list:\n",
    "    if item not in side_effect_dict.keys():\n",
    "        side_effect_dict[item] = side_effect_repeated_list.count(item)\n",
    "\n",
    "print \"Done\"\n",
    "\n",
    "# Writing the Side Effect Dict into file\n",
    "\n",
    "print len(side_effect_dict.keys())\n",
    "f = open(\"Data/Final_Datasets/Id_Mapping_Files/Side_effects_Distribution.txt\",\"w\")\n",
    "f.write(json.dumps(side_effect_dict, indent=3))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#IMPORTANT\n",
    "# This cell's code should only be run if you wish to remove certain reported side effects based on their frequency.\n",
    "# The code here will remvoe all those side effects that do not ge repeated more than twice in the whole list of side \n",
    "# effects reported by all patients, hence the name Cutoff-2\n",
    "# DO NOT run if you do not wish to have any cutoffs.\n",
    "# You can change the number to have cutoffs accordingly.\n",
    "\n",
    "with open('Data/Final_Datasets/Side_Effects_Id.txt') as data_file:    \n",
    "    side_effect_id = json.load(data_file)   \n",
    "    \n",
    "print len(side_effect_dict.keys())\n",
    "\n",
    "# Taking Cutoff 2: Removing those side effects that do not get repeated more than 2 time\n",
    "useless_side_effect = []\n",
    "for key in side_effect_id.keys():\n",
    "    _id =  side_effect_id[key]\n",
    "    if side_effect_dict[_id] <= 2:        # Case of side effect repeating once: Add it to useless category\n",
    "        useless_side_effect.append(key)\n",
    "\n",
    "for item in useless_side_effect:\n",
    "    f = open(\"Data/Final_Datasets/Useless/Useless_Side_Effect_2.txt\",'a')\n",
    "    f.write(\"%s\\n\"% item)\n",
    "\n",
    "print len(useless_side_effect)\n",
    "print \"Carefull About APPENDING\"\n",
    "\n",
    "# Cutoff-2\n",
    "# Removing those evaluations which reported side effect that were repeated not more than twice\n",
    "# Creating a new patient feature file that only have evaluations which staisfy the constraint of Cutoff-2\n",
    "\n",
    "for patient in patient_data.keys():\n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "        feature = patient_data[patient][\"Treatments List\"][drug][\"Side Effects\"]\n",
    "        temp = []\n",
    "        for item in feature:\n",
    "            if side_effect_dict[item] >2:\n",
    "                temp.append(item)        \n",
    "        if len(temp) == 0:\n",
    "            patient_data[patient][\"Treatments List\"].pop(drug, None)\n",
    "        else:\n",
    "            patient_data[patient][\"Treatments List\"][drug][\"Side Effects\"] = temp\n",
    "     \n",
    "    if len(patient_data[patient][\"Treatments List\"].keys()) == 0:\n",
    "        patient_data.pop(patient)\n",
    "\n",
    "print len(patient_data.keys())\n",
    "\n",
    "# Testing whether the above constraint has been implemented successsfully\n",
    "\n",
    "for patient in patient_data.keys():\n",
    "    if len(patient_data[patient][\"Treatments List\"].keys()) == 0:\n",
    "        print \"You are screwed\"\n",
    "        \n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "        feature = patient_data[patient][\"Treatments List\"][drug][\"Side Effects\"]\n",
    "        if len(feature) == 0:\n",
    "            print \"You are screwed\"\n",
    "        for item in feature:\n",
    "            if side_effect_dict[item] <= 2:\n",
    "                print \"You are screwed\"\n",
    "\n",
    "print \"Done\"\n",
    "\n",
    "f=open(\"Data/Final_Datasets/Cutoff_2/Total_Patients_Personal_Details_Features_File_2.txt\",\"w\")\n",
    "f.write( json.dumps(patient_data, indent=3, sort_keys=True) )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8011\n",
      "2109\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "patient_condition_data = {}\n",
    "\n",
    "# Making a vocabulary of all the conditions: primary and other listed by all the patients in dataset.\n",
    "# This vocabulary is stored in train_data. It is a dictionary with key as condition name and value as 1.0 if condition is \n",
    "# from a class of primary condition of patients and 0.5 if the condition is from class of other conditions.\n",
    "\n",
    "# Concatenating both primary and secodary conditions for each patient and assiging the concatenated list of conditions \n",
    "# for each patient in patient_condition_data. Key is patient and value is the concatenated list.\n",
    "# While making the concatenated list for each patient, we add \"P_\" at start of primary condition id \n",
    "# and \"O_\" for other condition id. This is to differentiate as there would a primary condition with id 1 and also an \n",
    "# other condition with id 1, so to differentiate between same id primary and other conditions, add these strings.\n",
    "\n",
    "for patient in patient_data.keys():\n",
    "    condition_list = []\n",
    "    feature = patient_data[patient][\"Primary Condition\"]\n",
    "    if feature != -1:\n",
    "        condition_list.append(\"P_\" + str(feature) )\n",
    "        train_data[ \"P_\" + str(feature) ] = 1             # Assigning score 1 for primary condition\n",
    "    \n",
    "    feature = patient_data[patient][\"Other conditions\"]\n",
    "    if feature != -1:\n",
    "        for item in feature:\n",
    "            condition_list.append( \"O_\" + str(item))\n",
    "            train_data[ \"O_\" + str(item) ] = 0.5          # Assigning score 0.5 for other conditions\n",
    " \n",
    "    patient_condition_data[ patient ] = condition_list\n",
    "\n",
    "f = open(\"Data/Final_Datasets/Condition_Features/Patient_Condition_Data.txt\",\"w\")\n",
    "f.write( json.dumps(patient_condition_data, indent=3, sort_keys=True) )\n",
    "f.close()\n",
    "\n",
    "f = open(\"Data/Final_Datasets/Condition_Features/Conditions_Vocaulary.txt\", \"w\")\n",
    "f.write( json.dumps(train_data, indent=3, sort_keys=True) )\n",
    "f.close()\n",
    "\n",
    "print len(patient_condition_data)\n",
    "print len(train_data)\n",
    "\n",
    "# Generating a vectorised representation for each patient's concatenated condition list\n",
    "# Vector is of size of length of vocabualary i.e. len(train_data.keys())\n",
    "# Every condition from patient's list of conditions i.e. patient_condition_data[patient] is compared \n",
    "# with list of conditions in vocabulary. \n",
    "# For those conditions of vocab present in patient's list condition, assign the score 1 or 0.5 depending on whether its primary or other condition\n",
    "# Else assign zero for that component of vector.\n",
    "\n",
    "vectorised_data ={}\n",
    "for patient in patient_condition_data:\n",
    "    temp = []\n",
    "    for condition in train_data.keys():\n",
    "        if condition in patient_condition_data[patient]:\n",
    "            temp.append( train_data[condition] )\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    vectorised_data[ patient ] = temp\n",
    "\n",
    "f = open(\"Data/Final_Datasets/Condition_Features/Vectorised_Patient_Condition.txt\", \"w\")\n",
    "f.write( json.dumps(vectorised_data, indent=3, sort_keys=True) )\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of evaluations 42075\n",
      "Total Number of Evaluations 42075\n",
      "Done with Librec File Generation\n"
     ]
    }
   ],
   "source": [
    "# Generating files for Librec: \n",
    "\n",
    "from mlxtend.preprocessing import OnehotTransactions\n",
    "\n",
    "total_eval_count = 0\n",
    "for patient in patient_data.keys():\n",
    "    content1 = patient_id[patient]\n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "        content2 = int(drug)\n",
    "        content3 = patient_data[patient][\"Treatments List\"][drug][\"Side Effect Rating\"]\n",
    "\n",
    "        f = open(\"Data/Final_Datasets/Librec Side Effects Rating New.txt\",'a')\n",
    "        f.write(\"%s \"% content1 )\n",
    "        f.write(\"%s \"% content2 )\n",
    "        f.write(\"%s\\n\"% content3 )\n",
    "        total_eval_count = total_eval_count + 1\n",
    "\n",
    "print \"Total Number of evaluations\",\n",
    "print total_eval_count\n",
    "\n",
    "# Make a list of all the Side Effects, so that we can convert it to One Hot Notation\n",
    "side_effect_list = []\n",
    "for patient in patient_data.keys():\n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "        side_effect_list.append( patient_data[patient][\"Treatments List\"][drug][\"Side Effects\"] )\n",
    "                    \n",
    "# Converting to One Hot Vector\n",
    "convert= OnehotTransactions()\n",
    "side_effect_list = convert.fit( side_effect_list ).transform( side_effect_list )\n",
    "\n",
    "# Making the Librec Dictionary\n",
    "side_effect_counter = 0\n",
    "librec_dict = {}\n",
    "\n",
    "for patient in patient_data.keys():\n",
    "    patient_counter = patient_id[patient]\n",
    "    librec_dict[patient_counter] = {}\n",
    "    \n",
    "    for drug in patient_data[patient][\"Treatments List\"].keys():\n",
    "        key = int(drug)\n",
    "        librec_dict[patient_counter][key] = {}\n",
    "        librec_dict[patient_counter][key][\"Side Effect Rating\"] = patient_data[patient][\"Treatments List\"][drug][\"Side Effect Rating\"]    \n",
    "        librec_dict[patient_counter][key][\"Primary Condition\"] = patient_data[patient][\"Primary Condition\"]\n",
    "        librec_dict[patient_counter][key][\"Side Effects\"] = side_effect_list[ side_effect_counter ].tolist() \n",
    "        librec_dict[patient_counter][key][\"Condition\"] = vectorised_data[patient]\n",
    "            \n",
    "        side_effect_counter = side_effect_counter + 1\n",
    "\n",
    "print \"Total Number of Evaluations\",\n",
    "print side_effect_counter\n",
    "\n",
    "f= open(\"Data/Final_Datasets/Complete_Vectorised_Features_Data.txt\",\"w\")\n",
    "json.dump(librec_dict, f)\n",
    "f.close()\n",
    "\n",
    "print \"Done with Librec File Generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
